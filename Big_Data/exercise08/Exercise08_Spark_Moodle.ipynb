{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for the moodle exercise in Spark\n",
    "\n",
    "In this jupyter notebook we are going to make the preprocessing part of the dataset that is going to be used in the graded exercise of this week.\n",
    "1. Change to exercise08 repository\n",
    "\n",
    "2. Start docker <br>\n",
    "docker-compose up -d\n",
    "\n",
    "3. Getting the data:\n",
    "Follow the procedure that is described below. The dataset can be found here: http://data.greatlanguagegame.com.s3.amazonaws.com/confusion-2014-03-02.tbz2. More specifically do the following:\n",
    "- download the data      :<br> ```wget http://data.greatlanguagegame.com.s3.amazonaws.com/confusion-2014-03-02.tbz2```\n",
    "- extract the data       :<br> ```tar -jxvf confusion-2014-03-02.tbz2```\n",
    "\n",
    "4. Go into the folder of the dataset:  ```cd confusion-2014-03-02```\n",
    "\n",
    "5. Extract the part of the dataset that we will work with in this exercise: ```head -n 3000000 confusion-2014-03-02.json > confusion-part.json```\n",
    "\n",
    "\n",
    "For more information about the dataset, you can refer to https://lars.yencken.org/datasets/great-language-game/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing commands\n",
    "In your newly created notebook run these commands in order to have the dataset into an RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "spark = SparkSession.builder.master('local').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "path = \"confusion-2014-03-02/confusion-part.json\"\n",
    "raw_data = sc.textFile(path)\n",
    "dataset = raw_data.map(json.loads).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that you will be able to run the queries of the moodle question of this week. The RDD that you have to perform your queries on is the ```dataset``` one. For example, the following command returns one element of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'guess': 'Norwegian',\n",
       "  'target': 'Norwegian',\n",
       "  'country': 'AU',\n",
       "  'choices': ['Maori', 'Mandarin', 'Norwegian', 'Tongan'],\n",
       "  'sample': '48f9c924e0d98c959d8a6f1862b3ce9a',\n",
       "  'date': '2013-08-19'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42245"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter\n",
    "task1 = dataset.filter(lambda i: i['guess'] == 'Norwegian' and i['target'] == 'Norwegian')\n",
    "task1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task2 = dataset.map(lambda i: i['guess']).distinct()\n",
    "task2.collect()\n",
    "task2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'guess': 'Albanian',\n",
       "  'target': 'Albanian',\n",
       "  'country': 'A1',\n",
       "  'choices': ['Albanian', 'Macedonian'],\n",
       "  'sample': '00b85faa8b878a14f8781be334deb137',\n",
       "  'date': '2013-09-04'},\n",
       " {'guess': 'Albanian',\n",
       "  'target': 'Albanian',\n",
       "  'country': 'A1',\n",
       "  'choices': ['Albanian', 'Bulgarian', 'Indonesian', 'Portuguese'],\n",
       "  'sample': 'efcd813daec1c836d9f030b30caa07ce',\n",
       "  'date': '2013-09-05'},\n",
       " {'guess': 'Albanian',\n",
       "  'target': 'Albanian',\n",
       "  'country': 'A1',\n",
       "  'choices': ['Albanian', 'Hindi', 'Swahili'],\n",
       "  'sample': '13722ceed1eede7ba597ade9b4cb9807',\n",
       "  'date': '2013-09-08'},\n",
       " {'guess': 'Albanian',\n",
       "  'target': 'Albanian',\n",
       "  'country': 'A1',\n",
       "  'choices': ['Albanian', 'Tamil'],\n",
       "  'sample': 'efcd813daec1c836d9f030b30caa07ce',\n",
       "  'date': '2013-09-08'},\n",
       " {'guess': 'Albanian',\n",
       "  'target': 'Albanian',\n",
       "  'country': 'A1',\n",
       "  'choices': ['Albanian', 'Urdu'],\n",
       "  'sample': 'efcd813daec1c836d9f030b30caa07ce',\n",
       "  'date': '2013-09-08'},\n",
       " {'guess': 'Albanian',\n",
       "  'target': 'Albanian',\n",
       "  'country': 'A1',\n",
       "  'choices': ['Albanian', 'Nepali'],\n",
       "  'sample': '1dd8e1883037c6305b87afe382c4feba',\n",
       "  'date': '2013-09-08'},\n",
       " {'guess': 'Albanian',\n",
       "  'target': 'Albanian',\n",
       "  'country': 'A2',\n",
       "  'choices': ['Albanian', 'Italian', 'Ukrainian'],\n",
       "  'sample': 'fdf23d0a7063ba2fcef4b18eb7d57ad8',\n",
       "  'date': '2013-09-06'},\n",
       " {'guess': 'Albanian',\n",
       "  'target': 'Albanian',\n",
       "  'country': 'A2',\n",
       "  'choices': ['Albanian', 'Bulgarian', 'Gujarati', 'Ukrainian'],\n",
       "  'sample': 'fdf23d0a7063ba2fcef4b18eb7d57ad8',\n",
       "  'date': '2013-09-06'},\n",
       " {'guess': 'Albanian',\n",
       "  'target': 'Albanian',\n",
       "  'country': 'A2',\n",
       "  'choices': ['Albanian',\n",
       "   'Cantonese',\n",
       "   'Dari',\n",
       "   'German',\n",
       "   'Norwegian',\n",
       "   'Swedish'],\n",
       "  'sample': 'fdf23d0a7063ba2fcef4b18eb7d57ad8',\n",
       "  'date': '2013-09-06'},\n",
       " {'guess': 'Albanian',\n",
       "  'target': 'Albanian',\n",
       "  'country': 'AE',\n",
       "  'choices': ['Albanian', 'Urdu'],\n",
       "  'sample': 'fdf23d0a7063ba2fcef4b18eb7d57ad8',\n",
       "  'date': '2013-09-03'}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task3 = dataset.filter(lambda i: i['guess'] == i['target'])\n",
    "task3b = task3.sortBy(lambda x: (x['target'], x['country'],  x['date']), ascending=(False, True, False))\n",
    "task3b.take(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample ID of the top game where the guessed language is correct: 00b85faa8b878a14f8781be334deb137\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Filter records where the guessed language is correct\n",
    "correct_guess_rdd = dataset.filter(lambda record: record['guess'] == record['target'])\n",
    "\n",
    "# 2. Sort the filtered records by target language (descending), then by country (ascending), and date (descending)\n",
    "sorted_records = correct_guess_rdd.sortBy(lambda record: (record['target'], record['country'], record['date']), ascending=[False, True, False])\n",
    "\n",
    "# 3. Take the top record and extract the sample ID\n",
    "top_record = sorted_records.first()\n",
    "top_sample_id = top_record['sample']\n",
    "\n",
    "# Print the result\n",
    "print(f\"Sample ID of the top game where the guessed language is correct: {top_sample_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('US', 'German'), 20932), (('US', 'French'), 20780)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task4 = dataset.map(lambda x: ((x['country'], x['guess']), x['sample'])).groupByKey().mapValues(len)\n",
    "task4TopTwo = task4.takeOrdered(2, key=lambda x: -x[1])\n",
    "task4TopTwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20932,20780\n"
     ]
    }
   ],
   "source": [
    "mapped_rdd = dataset.map(lambda record: ((record['country'], record['guess']), 1))\n",
    "\n",
    "# Reduce by key to count the occurrences of each key\n",
    "counted_rdd = mapped_rdd.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# Sort the results in descending order based on the count\n",
    "sorted_rdd = counted_rdd.sortBy(lambda x: x[1], ascending=False)\n",
    "\n",
    "# Take the top two elements\n",
    "top_two = sorted_rdd.take(2)\n",
    "\n",
    "# Extract the counts from the result\n",
    "count1, count2 = [count for (key, count) in top_two]\n",
    "\n",
    "# Print the result\n",
    "print(f\"{count1},{count2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25385233333333335\n"
     ]
    }
   ],
   "source": [
    "task5a = dataset.filter(lambda i: i['guess'] == i['target'] and i['choices'][0] == i['target']).count()\n",
    "task5b = dataset.count()\n",
    "print(task5a/task5b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25385233333333335"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Filter records where the guess is correct\n",
    "correct_guess_rdd = dataset.filter(lambda record: record['guess'] == record['target'])\n",
    "\n",
    "# 2. Further filter records where the correct guess is the first choice\n",
    "correct_first_choice_rdd = correct_guess_rdd.filter(lambda record: record['guess'] == record['choices'][0])\n",
    "\n",
    "# 3. Calculate the percentage\n",
    "total_games = dataset.count()\n",
    "correct_first_choice_percentage = (correct_first_choice_rdd.count() / total_games)\n",
    "\n",
    "# Print the result\n",
    "correct_first_choice_percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Maltese', <pyspark.resultiterable.ResultIterable at 0x7f797c3357f0>),\n",
       " ('Tagalog', <pyspark.resultiterable.ResultIterable at 0x7f797c335ac0>),\n",
       " ('Danish', <pyspark.resultiterable.ResultIterable at 0x7f797c335700>),\n",
       " ('Gujarati', <pyspark.resultiterable.ResultIterable at 0x7f797c335940>),\n",
       " ('Hungarian', <pyspark.resultiterable.ResultIterable at 0x7f797c335a30>),\n",
       " ('Somali', <pyspark.resultiterable.ResultIterable at 0x7f797c277700>),\n",
       " ('Khmer', <pyspark.resultiterable.ResultIterable at 0x7f797c277790>),\n",
       " ('Latvian', <pyspark.resultiterable.ResultIterable at 0x7f797c2776d0>),\n",
       " ('Bulgarian', <pyspark.resultiterable.ResultIterable at 0x7f797c277820>),\n",
       " ('Slovak', <pyspark.resultiterable.ResultIterable at 0x7f797c277670>)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task6b = dataset.map(lambda x: (x['target'], x['guess'])).foldByKey((0,0), lambda x: if x[0] == x[1])\n",
    "task6b.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: South Efate, Percentage of Correct Guesses: 0.36936936936936937\n",
      "Language: Hausa, Percentage of Correct Guesses: 0.390007745933385\n",
      "Language: Shona, Percentage of Correct Guesses: 0.4151898734177215\n"
     ]
    }
   ],
   "source": [
    "# Filter records where 'guess' is equal to 'target'\n",
    "correct_guesses = dataset.filter(lambda x: x['guess'] == x['target'])\n",
    "\n",
    "# Count the number of correct guesses for each language\n",
    "correct_guess_count = correct_guesses.map(lambda x: (x['guess'], 1)).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# Count the total number of guesses for each language\n",
    "total_guess_count = dataset.map(lambda x: (x['guess'], 1)).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# Calculate the percentage of correct guesses for each language\n",
    "percentage_correct = correct_guess_count.join(total_guess_count).map(lambda x: (x[0], x[1][0] / x[1][1]))\n",
    "\n",
    "# Sort the languages by decreasing overall percentage of correct guesses\n",
    "sorted_percentage = percentage_correct.sortBy(lambda x: x[1], ascending=True)\n",
    "\n",
    "# Get the last three languages\n",
    "last_three_languages = sorted_percentage.take(3)\n",
    "\n",
    "# Print the result\n",
    "for language, percentage in last_three_languages:\n",
    "    print(f\"Language: {language}, Percentage of Correct Guesses: {percentage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "South Efate,Hausa,Shona\n"
     ]
    }
   ],
   "source": [
    "correct_guess_rdd = dataset.filter(lambda record: record['guess'] == record['target'])\n",
    "\n",
    "# 2. Calculate the overall percentage of correct guesses for each language\n",
    "language_correct_counts = correct_guess_rdd.map(lambda record: (record['guess'], 1)).reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "language_total_counts = dataset.map(lambda record: (record['guess'], 1)).reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "language_percentages = language_correct_counts.join(language_total_counts).map(lambda x: (x[0], x[1][0] / x[1][1] * 100))\n",
    "\n",
    "# 3. Sort the languages by decreasing overall percentage\n",
    "sorted_languages = language_percentages.sortBy(lambda x: x[1], ascending=True)\n",
    "\n",
    "# 4. Take the last three languages\n",
    "last_three_languages = sorted_languages.take(3)\n",
    "\n",
    "# Extract the languages from the result\n",
    "language1, language2, language3 = [language for (language, percentage) in last_three_languages]\n",
    "\n",
    "# Print the result\n",
    "print(f\"{language1},{language2},{language3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2013-09-09',\n",
       " '2013-09-08',\n",
       " '2013-09-07',\n",
       " '2013-09-06',\n",
       " '2013-09-05',\n",
       " '2013-09-04',\n",
       " '2013-09-03',\n",
       " '2013-09-02',\n",
       " '2013-09-01',\n",
       " '2013-08-31',\n",
       " '2013-08-29',\n",
       " '2013-08-28',\n",
       " '2013-08-27',\n",
       " '2013-08-26',\n",
       " '2013-08-25',\n",
       " '2013-08-24',\n",
       " '2013-08-23',\n",
       " '2013-08-22',\n",
       " '2013-08-21',\n",
       " '2013-08-20',\n",
       " '2013-08-19']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task7a = dataset.map(lambda x: x['date']).distinct().sortBy(lambda x: (x), ascending=(False))\n",
    "task7a.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430894"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task7b = dataset.filter(lambda x : x['date'] == '2013-09-08').count()\n",
    "task7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games played on the second-to-latest day: 430894\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Find distinct dates and sort them in descending order based on the string\n",
    "distinct_dates = dataset.map(lambda record: record['date']).distinct().sortBy(lambda x: x, ascending=False)\n",
    "\n",
    "# 2. Take the second date in the sorted list\n",
    "second_to_latest_date = distinct_dates.take(2)[-1]\n",
    "\n",
    "# 3. Filter the RDD to include only records with that date\n",
    "games_on_second_to_latest_day = dataset.filter(lambda record: record['date'] == second_to_latest_date)\n",
    "\n",
    "# 4. Count the number of games played on the second-to-latest day\n",
    "number_of_games = games_on_second_to_latest_day.count()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of games played on the second-to-latest day: {number_of_games}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
